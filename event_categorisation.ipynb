{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(\"./filestore/events/fact_events.csv\").drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>headcount</th>\n",
       "      <th>event_id</th>\n",
       "      <th>maybe_rsvp_count</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>rsvp_limit</th>\n",
       "      <th>status</th>\n",
       "      <th>time</th>\n",
       "      <th>updated</th>\n",
       "      <th>utc_offset</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>visibility</th>\n",
       "      <th>waitlist_count</th>\n",
       "      <th>yes_rsvp_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>These meetups are very informal. I won't be st...</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>147478282</td>\n",
       "      <td>0</td>\n",
       "      <td>PyLadies Dublin Inaugural meetup - bring laptop!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>past</td>\n",
       "      <td>1384799400000</td>\n",
       "      <td>1384853013000</td>\n",
       "      <td>0</td>\n",
       "      <td>16176442</td>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Our second meetup will be at Engine Yard, a bi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>152107272</td>\n",
       "      <td>0</td>\n",
       "      <td>Second PyLadies Dublin Meetup - Let's get coding!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>past</td>\n",
       "      <td>1387218600000</td>\n",
       "      <td>1387230236000</td>\n",
       "      <td>0</td>\n",
       "      <td>13054852</td>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Happy New Year! Hope you all had a good Christ...</td>\n",
       "      <td>10800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>159368332</td>\n",
       "      <td>0</td>\n",
       "      <td>Our first PyLadies Dublin meetup of 2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>past</td>\n",
       "      <td>1390240800000</td>\n",
       "      <td>1390470097000</td>\n",
       "      <td>0</td>\n",
       "      <td>17757332</td>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Bring your laptops along. If you want some foo...</td>\n",
       "      <td>10800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>162851382</td>\n",
       "      <td>0</td>\n",
       "      <td>PyLadies Dublin Feb meetup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>past</td>\n",
       "      <td>1392660000000</td>\n",
       "      <td>1392672314000</td>\n",
       "      <td>0</td>\n",
       "      <td>18096492</td>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>!!!CHANGE OF VENUE UPDATE!!! &amp;gt;&amp;gt; More inf...</td>\n",
       "      <td>10800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>166955082</td>\n",
       "      <td>0</td>\n",
       "      <td>PyLadies Dublin Meetup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>past</td>\n",
       "      <td>1395165600000</td>\n",
       "      <td>1395219566000</td>\n",
       "      <td>0</td>\n",
       "      <td>18950322</td>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description    duration  headcount  \\\n",
       "0  These meetups are very informal. I won't be st...   9000000.0         12   \n",
       "1  Our second meetup will be at Engine Yard, a bi...         NaN          0   \n",
       "2  Happy New Year! Hope you all had a good Christ...  10800000.0          0   \n",
       "3  Bring your laptops along. If you want some foo...  10800000.0          0   \n",
       "4  !!!CHANGE OF VENUE UPDATE!!! &gt;&gt; More inf...  10800000.0          0   \n",
       "\n",
       "    event_id  maybe_rsvp_count  \\\n",
       "0  147478282                 0   \n",
       "1  152107272                 0   \n",
       "2  159368332                 0   \n",
       "3  162851382                 0   \n",
       "4  166955082                 0   \n",
       "\n",
       "                                                name  rating  rsvp_limit  \\\n",
       "0   PyLadies Dublin Inaugural meetup - bring laptop!     NaN         NaN   \n",
       "1  Second PyLadies Dublin Meetup - Let's get coding!     NaN         NaN   \n",
       "2           Our first PyLadies Dublin meetup of 2014     NaN         NaN   \n",
       "3                         PyLadies Dublin Feb meetup     NaN         NaN   \n",
       "4                             PyLadies Dublin Meetup     NaN         NaN   \n",
       "\n",
       "  status           time        updated  utc_offset  venue_id visibility  \\\n",
       "0   past  1384799400000  1384853013000           0  16176442     public   \n",
       "1   past  1387218600000  1387230236000           0  13054852     public   \n",
       "2   past  1390240800000  1390470097000           0  17757332     public   \n",
       "3   past  1392660000000  1392672314000           0  18096492     public   \n",
       "4   past  1395165600000  1395219566000           0  18950322     public   \n",
       "\n",
       "   waitlist_count  yes_rsvp_count  \n",
       "0               0              22  \n",
       "1               0              12  \n",
       "2               0              11  \n",
       "3               0               9  \n",
       "4               0              11  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description          object\n",
       "duration            float64\n",
       "headcount             int64\n",
       "event_id             object\n",
       "maybe_rsvp_count      int64\n",
       "name                 object\n",
       "rating              float64\n",
       "rsvp_limit          float64\n",
       "status               object\n",
       "time                  int64\n",
       "updated               int64\n",
       "utc_offset            int64\n",
       "venue_id              int64\n",
       "visibility           object\n",
       "waitlist_count        int64\n",
       "yes_rsvp_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at the event descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = events['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are delighted to announce that Metricfire will be hosting our Feb meetup. (Recap: January notes :\\xa0https://pyladiesdublin.hackpad.com/PyLadies-Dublin-Jan-2015-Notes-ozFxnmsIWqs) Feel free to update Feb notes to let us know what you are working on:\\xa0https://pyladiesdublin.hackpad.com/PyLadies-Dublin-Feb-2015-Notes-dmz4ESRJJsg Join our\\xa0mailing list\\xa0for discussions and sharing all things Python-y as well as Python-related events.\\xa0 This event is\\xa0FREE\\xa0and is suitable for\\xa0ALL\\xa0levels. Questions? Ping Vicky at [masked] ABOUT METRICFIRE  Metricfire run a service called Hosted Graphite. Hosted Graphite is a hosted version of the popular Graphite open source\\xa0metric and monitoring software, and we have customers all over the\\xa0world. We provide a metrics platform to developers to allow them tomeasure their applications and servers. Companies send large amounts of\\xa0metric data to us (125,000 data points per second or roughly 10 billion\\xa0per day), which we store, graph and display on visual dashboards. We are\\xa06 engineers in Dublin and one in the US. http://www.metricfire.com'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unicode, URLS, smiley faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_dict = {\n",
    "    'smile' : r'[:;=]-[)D]?',\n",
    "    'uni' : r'\\xa0',\n",
    "    'dupe_space' : r'\\s{2,}|\\s\\Z',\n",
    "    'url' : r'(?:https?|ftp|file)://\\S+',\n",
    "    'uls_chars' :  r'(?:&[gla][tm]p?)+'\n",
    "}\n",
    "\n",
    "def remove_special(s):\n",
    "    for k, regex in special_dict.items():\n",
    "        if k == 'uni':\n",
    "            s = re.sub(regex, ' ', s)\n",
    "        else:\n",
    "            s = re.sub(regex, '', s)\n",
    "    return s\n",
    "\n",
    "clean_special = [remove_special(s).lower() for s in desc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation and emojis\n",
    "There are some emoji characters and unwanted punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unwanted_chars(s):\n",
    "#     pattern = r\"[^a-zA-Z0-9\\s.\\-/':!?&@€$_+Éáéóć%]\"\n",
    "    pattern = r\"[^a-zA-Z0-9\\s/@€$_+Éáéóć%]\"\n",
    "    return set(re.findall(pattern, s))\n",
    "\n",
    "unwanted = set(char for e in desc for char in find_unwanted_chars(e))\n",
    "clean_punct = []\n",
    "\n",
    "for sent in clean_special:\n",
    "    for punct in unwanted:\n",
    "        sent = sent.replace(punct, \"\")\n",
    "    clean_punct.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workday will be hosting us for our july meetup food and refreshments will also be providedwe have two speakers from workday  amanda galligan  principal network engineer will do a talk on ansible a network engineers best friend  alan kennedy  principal software development engineer infra services will also do a talk on writing network services using python coroutines naomi oreilly  qa engineer grid cloud master will be conducting a talk on bdd in python  an introduction to behaviour driven development in python with a focus on automated acceptance testing remember to bring your laptop you will have a chance to deep dive with speakers pair programme on a tutorial a project could even be your own ask a question dont be shy we are here to helpif you have announcements events projects questions feel free to add them to  rough running order 1830 guests arrive  food  beverages1900 welcome  announcements by vicky1905 quick word from workday representative1910 lightning talk 11925 lightning talk 21940 lightning talk 3until 2100 deep dive with speakers selfdriven tutorials own projects pair programming ask for help chitchat etc  call for speakers interested in speaking at our upcoming meetups please submit talk details to  questionsemail masked were positively disrupting the enterprise software industry through the hard work and pioneering spirit of our amazing employees were committed to bringing passion and customer focus to the business of enterprise applications we work hard and were serious about what we do but we like to have a good time too in fact we run our company with that principle in mind every day one of our core values is fun'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_punct[47]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing words that have digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason for this is that after tokenizing, I found that there are tokens which consist of digits (perhaps meetup start/end times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(s):\n",
    "    pattern = re.compile(r'\\b(?:\\d+\\S+|\\S+\\d+)\\b')\n",
    "    return re.sub(pattern, '', s)\n",
    "\n",
    "clean_digits = [remove_digits(s) for s in clean_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workday will be hosting us for our july meetup food and refreshments will also be providedwe have two speakers from workday  amanda galligan  principal network engineer will do a talk on ansible a network engineers best friend  alan kennedy  principal software development engineer infra services will also do a talk on writing network services using python coroutines naomi oreilly  qa engineer grid cloud master will be conducting a talk on bdd in python  an introduction to behaviour driven development in python with a focus on automated acceptance testing remember to bring your laptop you will have a chance to deep dive with speakers pair programme on a tutorial a project could even be your own ask a question dont be shy we are here to helpif you have announcements events projects questions feel free to add them to  rough running order  guests arrive  food   welcome  announcements by  quick word from workday  lightning talk  lightning talk  lightning talk   deep dive with speakers selfdriven tutorials own projects pair programming ask for help chitchat etc  call for speakers interested in speaking at our upcoming meetups please submit talk details to  questionsemail masked were positively disrupting the enterprise software industry through the hard work and pioneering spirit of our amazing employees were committed to bringing passion and customer focus to the business of enterprise applications we work hard and were serious about what we do but we like to have a good time too in fact we run our company with that principle in mind every day one of our core values is fun'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_digits[47]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_text = clean_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stopwords = [\n",
    "    'python', 'speaker', 'speakers', 'dublin', 'ireland', 'pyladies',\n",
    "    'talk', 'talks', 'irish', 'james', 'julie', 'leticia', 'charlie',\n",
    "    'michael', 'marjai', 'atmasked', 'masked', 'isabella', 'annie',\n",
    "    'lowney', 'daire', 'amaral', 'carlos', 'campbell', 'chris', \n",
    "    'docherty', 'louise', 'deepali', 'andrea', 'diarmuid', 'sorcha',\n",
    "    'jonathan', 'eamon', 'shane', 'stella', 'mclennan', 'ingrid',\n",
    "    'aimi', 'niamh', 'forgan', 'jans', 'sabine', 'vicky', 'ariane',\n",
    "    'kats', 'bourke', 'georges'\n",
    "]\n",
    "en_stopwords = en_stopwords + extra_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer splits our documents into a distribution of words.\n",
    " \n",
    "X is a term document matrix, where each document is a column and words are rows. The value associated to each cell is the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words = set(en_stopwords))\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(event_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorizer we got above is used as input for LDA or NMF to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn import metrics\n",
    "# from scipy.spatial.distance import cdist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have an idea of how many topics can there be, let's use the silhouette score as a measure of how many clusters we should have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = range(2,30)\n",
    "# distortions = []\n",
    "# silhouette_coeffs = []\n",
    "\n",
    "# for k in clusters:\n",
    "#     km = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10,verbose=0)\n",
    "#     km.fit(X_tfidf)\n",
    "    \n",
    "#     distortions.append(km.inertia_)\n",
    "#     silhouette_coeffs.append(metrics.silhouette_score(X_tfidf, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# plt.style.use('seaborn-darkgrid')\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# ax.plot(clusters, distortions, marker='o', color='b')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# plt.style.use('seaborn-darkgrid')\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# ax.bar(x=clusters, height=silhouette_coeffs, color='g')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the preprocessing done was not enough and the k-means algorithm is being too sensitive to the data. It could be worthwhile trying to extract the event descriptions manually as there are only 70 ish events..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a sample clustering for k=15, doesn't seem good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "# terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# for i in range(15):\n",
    "#     print(\"Cluster %d:\" % i, end='')\n",
    "#     for ind in order_centroids[i, :10]:\n",
    "#         print(' %s' % terms[ind], end='')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = set(en_stopwords))\n",
    "X_count = count_vectorizer.fit_transform(event_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(X_count.toarray(), columns= count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_counts = pd.DataFrame({\n",
    "    'word' : count_vectorizer.get_feature_names(),\n",
    "    'count' : count_df.T.apply(np.sum, axis=1)\n",
    "}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2345 feature names.\n",
      "Of which 0 start with digits and might be noisy values\n"
     ]
    }
   ],
   "source": [
    "feats = count_vectorizer.get_feature_names()\n",
    "digits = re.compile(r'^\\d+')\n",
    "\n",
    "print(f\"There are {len(feats)} feature names.\")\n",
    "print(f\"Of which {len([re.match(digits, f) for f in feats if re.match(digits, f)])} \\\n",
    "start with digits and might be noisy values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_counts.sort_values('count', ascending=False).iloc[:50,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the counts above, the text quality doesn't look good. I will apply some manual cleansing to the description to get a more accurate representation of the Event descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)# Load the LDA model from sk-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def print_topics(model, vectorizer, n_top_words):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, an attempt with just the CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweak the two parameters below\n",
    "number_topics = 15\n",
    "number_words = 10\n",
    "jobs = -1\n",
    "max_iter = 25\n",
    "\n",
    "alpha = None\n",
    "eta = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA with CountVectorizer:\n",
      "\n",
      "Topic #0:\n",
      "intercom products work free bring communication questions also details customers\n",
      "\n",
      "Topic #1:\n",
      "free notes event levels thanks suitable bring well working pythony\n",
      "\n",
      "Topic #2:\n",
      "udemy please meetup work build kubernetes groupon learning working short\n",
      "\n",
      "Topic #3:\n",
      "ai bring work projects meetup please free food laptop aol\n",
      "\n",
      "Topic #4:\n",
      "women new code people event tea thanks along night drinks\n",
      "\n",
      "Topic #5:\n",
      "workshop event get data beginners women mentors session tea coffee\n",
      "\n",
      "Topic #6:\n",
      "dbs business rte career us want one learn april right\n",
      "\n",
      "Topic #7:\n",
      "please details free meetups questions food call projects submit speaking\n",
      "\n",
      "Topic #8:\n",
      "lala prizes please need dont folks people know make find\n",
      "\n",
      "Topic #9:\n",
      "power round quiz patch facebook people team folks tech shout\n",
      "\n",
      "Topic #10:\n",
      "kx kdb frances bring bank systems markets testing major derivatives\n",
      "\n",
      "Topic #11:\n",
      "using data software us questions bring salon provided max laptop\n",
      "\n",
      "Topic #12:\n",
      "open tech data free evening event meetup also work bring\n",
      "\n",
      "Topic #13:\n",
      "workshop data flask room jupyter analysis rest rooms dataset explore\n",
      "\n",
      "Topic #14:\n",
      "us business bring month space know businesses big evening thanks\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the LDA model\n",
    "lda = LDA(\n",
    "    doc_topic_prior = alpha,\n",
    "    topic_word_prior = eta,\n",
    "    n_components=number_topics,\n",
    "    n_jobs = jobs,\n",
    "    max_iter=max_iter)\n",
    "lda.fit(X_count)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA with CountVectorizer:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA with tfidf vectorizer:\n",
      "\n",
      "Topic #0:\n",
      "etsy pyladiesdub analytics perform defining gaining describe pythonshort seek donnelly\n",
      "\n",
      "Topic #1:\n",
      "graphite metric per source popular called creation large sept craftnight\n",
      "\n",
      "Topic #2:\n",
      "engineers rte dit kx beginners mentors jupyter public irelands one\n",
      "\n",
      "Topic #3:\n",
      "contribute django optional missed far beginning goal creating two github\n",
      "\n",
      "Topic #4:\n",
      "tech makers via tool giving minutes image circuit pepper meet\n",
      "\n",
      "Topic #5:\n",
      "prizes qualtrics year apply anything facebook patch change cryptoparty street\n",
      "\n",
      "Topic #6:\n",
      "pytorch bank mansura innovation opened grand canal boigrandcanalsq wraps sandwiches\n",
      "\n",
      "Topic #7:\n",
      "lia patterns belowmore fill form graphite nemeth multi paradigmatic heres\n",
      "\n",
      "Topic #8:\n",
      "traffic networking deininger maker among analyse wireshark wire shark detailsnadja\n",
      "\n",
      "Topic #9:\n",
      "gallery week django foundation barge collab chq pad continuing providedplease\n",
      "\n",
      "Topic #10:\n",
      "ics kdb women find ict round max salon quiz organising\n",
      "\n",
      "Topic #11:\n",
      "free bring please meetup projects workshop questions event notes work\n",
      "\n",
      "Topic #12:\n",
      "ai comments goodreads leave may lightning post grad landscape api\n",
      "\n",
      "Topic #13:\n",
      "stop whats arrive functional pub techie engineering number phd geeks\n",
      "\n",
      "Topic #14:\n",
      "lala indeedcom infused whoop july raspberry pi lightning beveragesuntil milian\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the LDA model\n",
    "lda = LDA(\n",
    "    doc_topic_prior = alpha,\n",
    "    topic_word_prior = eta,\n",
    "    n_components=number_topics,\n",
    "    n_jobs = jobs,\n",
    "    max_iter=max_iter)\n",
    "lda.fit(X_tfidf)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA with tfidf vectorizer:\")\n",
    "print_topics(lda, tfidf_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "* Review LDA model to understand how to fine tune alpha and eta\n",
    "* Vizualize results to see if they make sense\n",
    "* NMF (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
